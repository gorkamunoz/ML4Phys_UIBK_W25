<h1>Evaluation</h1>
<i>Note: this is only valid for Task 1 and 2 and will be further updated for Task 3 in due time.</i>
<br>
<br>
Your codes will be automatically evaluated by the platform. The requirements for your uploaded code are the following:

<ul>
    <li> You must submit a ZIP file containing (at minimum) a file  <code>model.py</code>.
         Note that if you are loading a machine learning model, you must also add the weights to the folder. </li>
    <li> This file must contain (at minimum) a class called <code>model</code>, which will be used to make your predictions. </li>
    <li> You can use typical Python libraries such as <code>pytorch</code>, <code>numpy</code>, <code>scikit</code>, <code>fastai</code> and <code>pandas</code>. </li>
    <li> This class must have no input parameters when instantiating (i.e. <code>__init__</code> must not have inputs). </li>
    <li> The only compulsory method <code>pred</code>, which takes as input the data of each task (see Data for details on the format). 
          Note that the input data will be of same format as the training data. The output must be a one-dimensional tensor with the prediction of each input sample. </li>

</ul>

Here is an example of minimal, valid input code, which does random predictions for some given inputs:

<pre style="background: #f7f7f7; border: 1px solid #e1e1e8; border-radius: 4px; padding: 12px; overflow-x: auto; color: #333;">
<span style="color: #008000;">import</span> torch

<span style="color: #0000FF;">class</span> <span style="color: #B22222;">model</span>:
    <span style="color: #008000;">def</span> <span style="color: #B22222;">__init__</span>(self):
        <span style="color: #008000;">pass</span>
    
    <span style="color: #008000;">def</span> <span style="color: #B22222;">pred</span>(self, x):
        <span style="color: #008000;">return</span> torch.rand(x.shape[0])
</pre>


<p style="text-align: justify;"> After submitting your code, the platform will automatically run your predictions.
If your submission does not meet the specified requirements, your code may not run correctly and no predictions will be generated.
In that case, you can learn more by clicking on the corresponding submission in the <code>My Submissions</code> tab and then opening the <code>Logs</code> tab in the pop-up window.
If the error occurs during prediction (e.g., your model does not meet the platform requirements), it will appear under <code>Prediction Logs &gt; Ingestion stdout/stderr</code>.
If the error occurs during scoring (e.g., the output of your model has the wrong shape), it will appear under <code>Scoring Logs &gt; stdout/stderr</code>.</p>



